{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d42c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted: noFire\n",
      "Confidence: 0.9999998867511749\n",
      "Predicted: noFire\n",
      "Confidence: [3.234658e-08 1.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow \n",
    "import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import customtkinter as ctk\n",
    "import os\n",
    "\n",
    "\n",
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    " \n",
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "CLASSES_LIST = [\"fight\",\"noFight\"]\n",
    "FIRE_CLASSES_LIST = [\"Fire\",\"noFire\"]\n",
    "\n",
    "model_path = ''\n",
    "file_path = ''\n",
    "\n",
    "def predict_fire__video(video_file_path):\n",
    "    model=load_model(model_path)\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    " \n",
    "    # Get the width and height of the video.\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    " \n",
    "    # Declare a list to store video frames we will extract.\n",
    "    frames_list = []\n",
    "    \n",
    "    # Store the predicted class in the video.\n",
    "    predicted_class_name = ''\n",
    " \n",
    "    # Get the number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    " \n",
    "    # Calculate the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    " \n",
    "    # Iterating the number of times equal to the fixed length of sequence.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    " \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    " \n",
    "        success, frame = video_reader.read() \n",
    " \n",
    "        if not success:\n",
    "            break\n",
    " \n",
    "        # Resize the Frame to fixed Dimensions.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame.\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Appending the pre-processed frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    " \n",
    "    predicted_labels_probabilities = []\n",
    "    predicted_label_lst = []\n",
    "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
    "    avg = [0,0]\n",
    "    for i in range(SEQUENCE_LENGTH):\n",
    "        \n",
    "        predicted_labels_probabilities.append(model.predict(np.expand_dims(frames_list[i], axis = 0))[0])\n",
    "        avg[0] += predicted_labels_probabilities[len(predicted_labels_probabilities)-1][0]\n",
    "        avg[1] += predicted_labels_probabilities[len(predicted_labels_probabilities)-1][1]\n",
    "    \n",
    "    avg[0] /= 20\n",
    "    avg[1] /= 20\n",
    "    if avg[0] > avg[1]:\n",
    "        predicted_label = 0\n",
    "    else:\n",
    "        predicted_label = 1\n",
    "    \n",
    "    # Get the class name using the retrieved index.\n",
    "    predicted_class_name = FIRE_CLASSES_LIST[predicted_label]\n",
    "    \n",
    "    # Display the predicted class along with the prediction confidence.\n",
    "    print(f'Predicted: {predicted_class_name}\\nConfidence: {avg[predicted_label]}')\n",
    "        \n",
    "    confidence = str(predicted_labels_probabilities[predicted_label])\n",
    "    print(f'Predicted: {predicted_class_name}\\nConfidence: {confidence}')\n",
    "    Result = 'Predicted: ' + predicted_class_name + ' and Confidence: ' +str(avg[predicted_label]) \n",
    "\n",
    "    # Create a new label to display the result\n",
    "    result_label.configure(text=Result)\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "def model_with_transfer_learning():\n",
    "    global model_path\n",
    "    global file_path\n",
    "    global SEQUENCE_LENGTH\n",
    "    model_path = '../Resources/Models/With Transfer Learning.h5'\n",
    "    SEQUENCE_LENGTH=20\n",
    "    predict_video(file_path)\n",
    "\n",
    "def without_transfer_learning():\n",
    "    global SEQUENCE_LENGTH\n",
    "    global model_path\n",
    "    global file_path\n",
    "    SEQUENCE_LENGTH=20\n",
    "    model_path = '../Resources/Models/Without Transfer Learning.h5'\n",
    "    predict_video(file_path)\n",
    "\n",
    "def optic_model_with_transfer_learning():\n",
    "    global SEQUENCE_LENGTH\n",
    "    global model_path\n",
    "    global file_path\n",
    "    SEQUENCE_LENGTH=19\n",
    "    model_path = '../Resources/Models/Optic With Transfer Learning.h5'\n",
    "    predict_video(file_path)\n",
    "\n",
    "def optic_model_without_transfer_learning():\n",
    "    global SEQUENCE_LENGTH\n",
    "    global model_path\n",
    "    global file_path\n",
    "    SEQUENCE_LENGTH=19\n",
    "    model_path = '../Resources/Models/Optic Without Transfer Learning.h5'\n",
    "    predict_video(file_path)\n",
    "\n",
    "\n",
    "def fire_model():\n",
    "    global model_path\n",
    "    global file_path\n",
    "    model_path='../Resources/Models/fire_model_84.h5'\n",
    "    predict_fire__video(file_path)\n",
    "\n",
    "def predict_video(video_file_path):\n",
    "    global model_path\n",
    "    #pre trained model path, models available on google drive\n",
    "    MoBiLSTM_model=load_model(model_path) \n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    " \n",
    "    # Get the width and height of the video.\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    " \n",
    "    # Declare a list to store video frames we will extract.\n",
    "    frames_list = []\n",
    "    \n",
    "    # Store the predicted class in the video.\n",
    "    predicted_class_name = ''\n",
    " \n",
    "    # Get the number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    " \n",
    "    # Calculate the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    " \n",
    "    # Iterating the number of times equal to the fixed length of sequence.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    " \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    " \n",
    "        success, frame = video_reader.read() \n",
    " \n",
    "        if not success:\n",
    "            break\n",
    " \n",
    "        # Resize the Frame to fixed Dimensions.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame.\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Appending the pre-processed frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    " \n",
    "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
    "    predicted_labels_probabilities = MoBiLSTM_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
    " \n",
    "    # Get the index of class with highest probability.\n",
    "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
    " \n",
    "    # Get the class name using the retrieved index.\n",
    "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "    \n",
    "    confidence = str(predicted_labels_probabilities[predicted_label])\n",
    "    print(f'Predicted: {predicted_class_name}\\nConfidence: {confidence}')\n",
    "    Result = 'Predicted: ' + predicted_class_name + ' and Confidence: ' + confidence\n",
    "\n",
    "    # Create a new label to display the result\n",
    "    result_label.configure(text=Result)\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "def button_clicked():\n",
    "    global file_path\n",
    "    Result =''\n",
    "    file_path = ctk.filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        label.configure(text=\"Selected File: \" + file_name)\n",
    "        button_upload.pack_forget()  # Hide the \"Upload\" button\n",
    "        result_label.pack(pady=(30, 0))\n",
    "        fight_model1.pack(side=\"left\", padx=10, pady=(0, 10))  \n",
    "        fight_model2.pack(side=\"left\", padx=10, pady=(0, 10))\n",
    "        optic_without_transfer.pack(side=\"left\", padx=10, pady=(0, 10))  \n",
    "        optic_with_transfer.pack(side=\"left\", padx=10, pady=(0, 10))\n",
    "        fire_model.pack(side=\"left\", padx=10, pady=(0, 10))  \n",
    "     \n",
    "    else:\n",
    "        label.configure(text=\"No file selected\")\n",
    "\n",
    "def apply_model():\n",
    "    print(\"Applying model...\")  \n",
    "\n",
    "# Create a new tkinter window\n",
    "window = ctk.CTk()\n",
    "\n",
    "window.title(\"Intelligent Surveillance System\")\n",
    "\n",
    "window.minsize(width=400, height=300)\n",
    "\n",
    "window.resizable(True, True)  \n",
    "\n",
    "label = ctk.CTkLabel(window, text=\"No file selected\")\n",
    "label.pack(pady=(20, 0))\n",
    "\n",
    "button_upload = ctk.CTkButton(window, text=\"Upload\", command=button_clicked)\n",
    "button_upload.pack(pady=10)\n",
    "\n",
    "result_label = ctk.CTkLabel(window, text=\"Prediction and confidence will be Displayed \")\n",
    "result_label.pack(pady=(30, 0))\n",
    "result_label.pack_forget()\n",
    "\n",
    "fight_model1 = ctk.CTkButton(window, text=\"Transfer Learning\", command=model_with_transfer_learning)\n",
    "fight_model1.pack(side=\"left\", padx=10)  \n",
    "fight_model1.pack_forget()  \n",
    "\n",
    "fight_model2 = ctk.CTkButton(window, text=\"Without Transfer Learning\", command=without_transfer_learning)\n",
    "fight_model2.pack(side=\"left\", padx=10, pady=10) \n",
    "fight_model2.pack_forget()\n",
    "\n",
    "fire_model = ctk.CTkButton(window, text=\"Apply Fire Model\", command=fire_model)\n",
    "fire_model.pack(side=\"left\", padx=10, pady=10)  \n",
    "fire_model.pack_forget()\n",
    "\n",
    "optic_without_transfer = ctk.CTkButton(window, text=\"Optic Without Transfer Learning\", command=optic_model_without_transfer_learning)\n",
    "optic_without_transfer.pack(side=\"left\", padx=10)  \n",
    "optic_without_transfer.pack_forget()  \n",
    "\n",
    "optic_with_transfer = ctk.CTkButton(window, text=\"Optic with Transfer Learning\", command=optic_model_with_transfer_learning)\n",
    "optic_with_transfer.pack(side=\"left\", padx=10, pady=10) \n",
    "optic_with_transfer.pack_forget()\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926eb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
